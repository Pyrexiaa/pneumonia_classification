{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6wnzw-FY18jI",
    "outputId": "af2dddbe-06f7-4b70-e309-ab00b851a153"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1h3WmTxwDAKy2eRw0SCXcNVFdreuquRQN\n",
      "From (redirected): https://drive.google.com/uc?id=1h3WmTxwDAKy2eRw0SCXcNVFdreuquRQN&confirm=t&uuid=c468cc47-851d-484a-828c-ee87f8a2b79f\n",
      "To: /content/new_data.zip\n",
      "100%|██████████| 1.23G/1.23G [00:21<00:00, 58.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "import zipfile\n",
    "\n",
    "url = 'https://drive.google.com/uc?id=1h3WmTxwDAKy2eRw0SCXcNVFdreuquRQN'\n",
    "output = 'new_data.zip'\n",
    "gdown.download(url, output, quiet=False)\n",
    "\n",
    "# Unzip the new_data.zip file\n",
    "with zipfile.ZipFile(\"new_data.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "l7KkpyxL2K4t"
   },
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from skimage.measure import label, regionprops\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    ")\n",
    "from torch import nn, optim\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def resize_image(image, target_size=(224, 224)):\n",
    "    \"\"\"Resizes an input image to the specified target size.\n",
    "\n",
    "    Args:\n",
    "        image (PIL Image or Torch Tensor): Input image to be resized.\n",
    "        target_size (tuple): Desired output size (height, width).\n",
    "\n",
    "    Returns:\n",
    "        PIL Image: Resized image.\n",
    "\n",
    "    \"\"\"\n",
    "    transform = transforms.Resize(target_size)\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image = transforms.ToPILImage()(image)\n",
    "    return transform(image)\n",
    "\n",
    "\n",
    "def histogram_equalization(image):\n",
    "    \"\"\"Performs histogram equalization on a grayscale image and returns a tensor.\n",
    "\n",
    "    Args:\n",
    "        image (PIL Image or Torch Tensor): Input grayscale image.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Equalized image as a tensor.\n",
    "\n",
    "    \"\"\"\n",
    "    # Convert the image to a NumPy array if it's a PIL Image\n",
    "    if isinstance(image, Image.Image):\n",
    "        image = np.array(image.convert(\"L\"))  # Convert to grayscale\n",
    "    elif isinstance(image, torch.Tensor):\n",
    "        image = image.numpy()\n",
    "\n",
    "    # Ensure the image is single-channel and np.uint8\n",
    "    if image.ndim == 3 and image.shape[0] == 1:  # If shape is (1, H, W)\n",
    "        image = image.squeeze(0)  # Remove the extra channel dimension\n",
    "    elif image.ndim == 3 and image.shape[-1] == 1:  # If shape is (H, W, 1)\n",
    "        image = image.squeeze(-1)\n",
    "\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "\n",
    "    equalized_image = cv2.equalizeHist(image)\n",
    "    equalized_pil_image = Image.fromarray(equalized_image)\n",
    "    # equalized_tensor = torch.from_numpy(equalized_image).float().unsqueeze(0)  # Add channel dimension for grayscale\n",
    "    return equalized_pil_image\n",
    "\n",
    "\n",
    "def gaussian_blur(image, kernel_size=(5, 5), sigma=0):\n",
    "    \"\"\"Applies Gaussian blur to a grayscale image.\n",
    "\n",
    "    Args:\n",
    "        image (PIL Image or Torch Tensor): Input grayscale image.\n",
    "        kernel_size (tuple): Size of the Gaussian kernel.\n",
    "        sigma (float): Standard deviation for Gaussian kernel.\n",
    "                       If 0, it will be calculated based on the kernel size.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Blurred image as a tensor.\n",
    "\n",
    "    \"\"\"  # noqa: D401\n",
    "    # Convert to NumPy array if the image is a PIL Image\n",
    "    if isinstance(image, Image.Image):\n",
    "        image = np.array(image)\n",
    "    elif isinstance(image, torch.Tensor):\n",
    "        # Convert to NumPy if the input is a tensor\n",
    "        image = image.numpy()\n",
    "\n",
    "    # If the image has a channel dimension (1, H, W), squeeze it to (H, W)\n",
    "    if image.ndim == 3 and image.shape[0] == 1:\n",
    "        image = np.squeeze(image, axis=0)\n",
    "\n",
    "    blurred_image = cv2.GaussianBlur(image, kernel_size, sigma)\n",
    "    blurred_tensor = (\n",
    "        torch.from_numpy(blurred_image).float().unsqueeze(0)\n",
    "    )  # Add channel dimension for grayscale\n",
    "\n",
    "    return blurred_tensor\n",
    "\n",
    "\n",
    "def bilateral_filter(image, diameter=5, sigma_color=75, sigma_space=75):\n",
    "    \"\"\"Applies a bilateral filter to a grayscale image.\n",
    "\n",
    "    Args:\n",
    "        image (PIL Image, NumPy array, or Torch Tensor): Input grayscale image.\n",
    "        diameter (int): Diameter of each pixel neighborhood used in the filter.\n",
    "        sigma_color (float): Filter sigma in the color space.\n",
    "        sigma_space (float): Filter sigma in the coordinate space.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Filtered image as a tensor.\n",
    "\n",
    "    \"\"\"  # noqa: D401\n",
    "    # Convert to NumPy array if the image is a PIL Image\n",
    "    if isinstance(image, Image.Image):\n",
    "        image = np.array(image)\n",
    "    elif isinstance(image, torch.Tensor):\n",
    "        image = image.numpy()\n",
    "\n",
    "    # If the image has a channel dimension (1, H, W), squeeze it to (H, W)\n",
    "    if image.ndim == 3 and image.shape[0] == 1:\n",
    "        image = np.squeeze(image, axis=0)\n",
    "\n",
    "    if image.dtype != np.uint8:\n",
    "        image = (255 * (image - image.min()) / (image.max() - image.min())).astype(\n",
    "            np.uint8\n",
    "        )\n",
    "\n",
    "    # Apply bilateral filter using OpenCV\n",
    "    filtered_image = cv2.bilateralFilter(image, diameter, sigma_color, sigma_space)\n",
    "\n",
    "    # Convert back to a PyTorch tensor\n",
    "    filtered_tensor = (\n",
    "        torch.from_numpy(filtered_image).float().unsqueeze(0)\n",
    "    )  # Add back channel dimension for grayscale\n",
    "\n",
    "    return filtered_tensor\n",
    "\n",
    "\n",
    "def adaptive_masking(image, closing_kernel_size=(5, 5)):\n",
    "    \"\"\"Applies adaptive masking by removing the diaphragm from a grayscale image.\n",
    "\n",
    "    Args:\n",
    "        image (PIL Image, NumPy array, or Torch Tensor): Input grayscale image.\n",
    "        closing_kernel_size (tuple): Size of the structuring element for morphological closing.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Image with diaphragm removed as a tensor.\n",
    "\n",
    "    \"\"\"\n",
    "    # Convert to NumPy array if the image is a PIL Image\n",
    "    if isinstance(image, Image.Image):\n",
    "        image = np.array(image.convert(\"L\"))  # Ensure grayscale\n",
    "    elif isinstance(image, torch.Tensor):\n",
    "        # Convert to NumPy if the input is a tensor\n",
    "        image = image.numpy()\n",
    "\n",
    "    # If the image has a channel dimension (1, H, W), squeeze it to (H, W)\n",
    "    if image.ndim == 3 and image.shape[0] == 1:\n",
    "        image = np.squeeze(image, axis=0)\n",
    "\n",
    "    # Step 1: Find max and min intensity values\n",
    "    min_intensity = np.min(image)\n",
    "    max_intensity = np.max(image)\n",
    "\n",
    "    # Step 2: Calculate threshold using the formula: threshold = min + 0.9 * (max - min)\n",
    "    threshold_value = min_intensity + 0.9 * (max_intensity - min_intensity)\n",
    "\n",
    "    # Step 3: Apply binary thresholding\n",
    "    _, binary_mask = cv2.threshold(image, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Step 4: Label connected regions and keep only the largest region\n",
    "    labeled_mask = label(binary_mask)\n",
    "    regions = regionprops(labeled_mask)\n",
    "    if not regions:\n",
    "        print(\"No regions found in the binary mask.\")\n",
    "        return torch.from_numpy(image).float().unsqueeze(0)\n",
    "\n",
    "    # Identify the largest connected region\n",
    "    largest_region = max(regions, key=lambda r: r.area)\n",
    "\n",
    "    # Create a mask with only the largest region filled\n",
    "    diaphragm_mask = np.zeros_like(binary_mask, dtype=np.uint8)\n",
    "    diaphragm_mask[labeled_mask == largest_region.label] = 255\n",
    "\n",
    "    # Step 5: Fill any holes in the diaphragm region\n",
    "    diaphragm_mask = cv2.morphologyEx(\n",
    "        diaphragm_mask, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8)\n",
    "    )\n",
    "\n",
    "    # Step 6: Apply morphological closing to smooth mask (remove small holes)\n",
    "    kernel = np.ones(closing_kernel_size, np.uint8)\n",
    "    diaphragm_mask = cv2.morphologyEx(diaphragm_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Step 7: Bitwise operation to remove diaphragm from the source image\n",
    "    result_image = cv2.bitwise_and(image, image, mask=cv2.bitwise_not(diaphragm_mask))\n",
    "\n",
    "    equalized_pil_image = Image.fromarray(result_image)\n",
    "\n",
    "    return equalized_pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1tJEApVH2PUJ"
   },
   "outputs": [],
   "source": [
    "preprocess_types = {\n",
    "    \"baseline\": [resize_image],\n",
    "    \"histogram_equalization\": [resize_image, histogram_equalization],\n",
    "    \"gaussian_blur\": [resize_image, histogram_equalization, gaussian_blur],\n",
    "    \"bilateral_filer\": [resize_image, histogram_equalization, bilateral_filter],\n",
    "    \"adaptive_masking\": [resize_image, adaptive_masking],\n",
    "    \"adaptive_masking_equalized\": [\n",
    "        resize_image,\n",
    "        adaptive_masking,\n",
    "        histogram_equalization,\n",
    "    ],\n",
    "    \"adaptive_masking_gaussian\": [\n",
    "        resize_image,\n",
    "        adaptive_masking,\n",
    "        histogram_equalization,\n",
    "        gaussian_blur,\n",
    "    ],\n",
    "    \"adaptive_masking_bilateral\": [\n",
    "        resize_image,\n",
    "        adaptive_masking,\n",
    "        histogram_equalization,\n",
    "        bilateral_filter,\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rP-yE0_P2Tom"
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10\n",
    "):\n",
    "    \"\"\"Trains and validates a model for a specified number of epochs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        model: PyTorch model\n",
    "        train_loader: DataLoader for training data\n",
    "        val_loader: DataLoader for validation data\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimizer\n",
    "        device: Device to train on ('cuda' or 'cpu')\n",
    "        num_epochs: Number of epochs\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        history: Dictionary containing training and validation loss and accuracy\n",
    "\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": [],\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = correct / total\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                _, predictions = torch.max(outputs, 1)\n",
    "                correct += (predictions == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_loss = running_loss / len(val_loader)\n",
    "        val_acc = correct / total\n",
    "\n",
    "        # Logging\n",
    "        print(f\"Train Loss: {train_loss:.4f} - Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Validation Loss: {val_loss:.4f} - Validation Acc: {val_acc:.4f}\")\n",
    "        print()\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    \"\"\"Tests a model on a test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        model: PyTorch model\n",
    "        test_loader: DataLoader for test data\n",
    "        device: Device to test on ('cuda' or 'cpu')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        y_true: True labels\n",
    "        y_pred: Predicted labels\n",
    "\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            y_true += labels.tolist()\n",
    "            y_pred += predictions.tolist()\n",
    "\n",
    "        # compute accuracy\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8q0h4kbW2U1H"
   },
   "outputs": [],
   "source": [
    "## Model pipeline\n",
    "def model_pipelines(\n",
    "    model,\n",
    "    model_name,\n",
    "    preprocess=None,\n",
    "    root=\"dataset/new_data\",\n",
    "    save_path=\"models_pretrained\",\n",
    "):\n",
    "    # Result table\n",
    "    results = np.array([[\"Preprocess\", \"Test Accuracy\"]])\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    # Loop through the preprocess_types\n",
    "    for key, value in preprocess_types.items():\n",
    "        functions = preprocess_types[key]\n",
    "        if preprocess is not None and key not in preprocess:\n",
    "            continue\n",
    "        print(f\"\\n===== {key} =====\")\n",
    "        transform = transforms.Compose(\n",
    "            functions\n",
    "            + [\n",
    "                transforms.Lambda(\n",
    "                    lambda x: x.convert(\"L\") if isinstance(x, Image.Image) else x\n",
    "                ),  # convert to grayscale\n",
    "                transforms.Lambda(\n",
    "                    lambda x: x\n",
    "                    if isinstance(x, torch.Tensor)\n",
    "                    else transforms.ToTensor()(x)\n",
    "                ),  # convert to tensor (To ensure torch.Size([1, 224, 224]))\n",
    "                transforms.Lambda(\n",
    "                    lambda x: x.repeat(3, 1, 1) if x.shape[0] == 1 else x\n",
    "                ),  # Convert single channel to RGB (3 channels)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        train_data = datasets.ImageFolder(root=f\"{root}/train\", transform=transform)\n",
    "        test_data = datasets.ImageFolder(root=f\"{root}/test\", transform=transform)\n",
    "        val_data = datasets.ImageFolder(root=f\"{root}/val\", transform=transform)\n",
    "\n",
    "        # Apply oversampling using imblearn\n",
    "        targets = [sample[1] for sample in train_data.imgs]  # Extract labels\n",
    "        sampler = RandomOverSampler(random_state=42)\n",
    "        indices = list(range(len(targets)))\n",
    "        resampled_indices, _ = sampler.fit_resample(np.array(indices).reshape(-1, 1), targets)\n",
    "        resampled_indices = resampled_indices.flatten()\n",
    "        resampled_dataset = Subset(train_data, resampled_indices)\n",
    "        print(f\"Original class distribution: {Counter(targets)}\")\n",
    "        print(f\"Resampled class distribution: {Counter([train_data.imgs[i][1] for i in resampled_indices])}\")\n",
    "\n",
    "\n",
    "        train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "        test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "        val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "\n",
    "        # Initialize the model\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = model.to(device)\n",
    "\n",
    "        # Define the loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        # Train the model\n",
    "        history = train_model(\n",
    "            model, train_loader, val_loader, criterion, optimizer, device, num_epochs=20\n",
    "        )\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy = test_model(model, test_loader, device)\n",
    "        torch.save(model, f\"{save_path}/{model_name}_{key}.pth\")\n",
    "        results = np.append(results, [[key, accuracy]], axis=0)\n",
    "        print(f\"Test Accuracy: {accuracy}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "w1njXXx52Zed"
   },
   "outputs": [],
   "source": [
    "## Define the CNN model\n",
    "class PneumoniaCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PneumoniaCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.dropout3 = nn.Dropout(0.4)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 512)\n",
    "        self.dropout4 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 3)  # Three classes: NORMAL, BACTERIA, VIRUS\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = x.view(-1, 128 * 28 * 28)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout4(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F1Zf8gPb2chT",
    "outputId": "a07850f6-6702-40fe-b550-19b3c0d4d690"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================\n",
      "DenseNet161 with adaptive_masking_bilateral\n",
      "=========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet161_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet161_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/densenet161-8d451a50.pth\" to /root/.cache/torch/hub/checkpoints/densenet161-8d451a50.pth\n",
      "100%|██████████| 110M/110M [00:00<00:00, 137MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== adaptive_masking_bilateral =====\n",
      "Original class distribution: Counter({0: 2338, 1: 1149, 2: 1145})\n",
      "Resampled class distribution: Counter({0: 2338, 1: 2338, 2: 2338})\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:59<00:00,  1.24s/it]\n",
      "Validation: 100%|██████████| 19/19 [00:15<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7176 - Train Acc: 0.7478\n",
      "Validation Loss: 0.7238 - Validation Acc: 0.7083\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:59<00:00,  1.24s/it]\n",
      "Validation: 100%|██████████| 19/19 [00:15<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4602 - Train Acc: 0.7964\n",
      "Validation Loss: 0.4850 - Validation Acc: 0.7767\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:57<00:00,  1.23s/it]\n",
      "Validation: 100%|██████████| 19/19 [00:15<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4380 - Train Acc: 0.8068\n",
      "Validation Loss: 0.4094 - Validation Acc: 0.8400\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:57<00:00,  1.22s/it]\n",
      "Validation: 100%|██████████| 19/19 [00:15<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4108 - Train Acc: 0.8184\n",
      "Validation Loss: 0.4155 - Validation Acc: 0.8150\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:57<00:00,  1.22s/it]\n",
      "Validation: 100%|██████████| 19/19 [00:15<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3857 - Train Acc: 0.8275\n",
      "Validation Loss: 0.4837 - Validation Acc: 0.7733\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:57<00:00,  1.23s/it]\n",
      "Validation: 100%|██████████| 19/19 [00:15<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3575 - Train Acc: 0.8394\n",
      "Validation Loss: 0.4385 - Validation Acc: 0.8067\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:57<00:00,  1.22s/it]\n",
      "Validation: 100%|██████████| 19/19 [00:15<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3537 - Train Acc: 0.8426\n",
      "Validation Loss: 0.6010 - Validation Acc: 0.7117\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:57<00:00,  1.23s/it]\n",
      "Validation: 100%|██████████| 19/19 [00:15<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3341 - Train Acc: 0.8538\n",
      "Validation Loss: 0.4544 - Validation Acc: 0.8050\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:58<00:00,  1.23s/it]\n",
      "Validation: 100%|██████████| 19/19 [00:15<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3083 - Train Acc: 0.8666\n",
      "Validation Loss: 0.4485 - Validation Acc: 0.8017\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:58<00:00,  1.23s/it]\n",
      "Validation: 100%|██████████| 19/19 [00:15<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2948 - Train Acc: 0.8715\n",
      "Validation Loss: 0.5470 - Validation Acc: 0.7667\n",
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:58<00:00,  1.23s/it]\n",
      "Validation: 100%|██████████| 19/19 [00:15<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2887 - Train Acc: 0.8748\n",
      "Validation Loss: 0.7104 - Validation Acc: 0.7450\n",
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [03:00<00:00,  1.25s/it]\n",
      "Validation: 100%|██████████| 19/19 [00:15<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2327 - Train Acc: 0.9026\n",
      "Validation Loss: 0.5279 - Validation Acc: 0.8150\n",
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:59<00:00,  1.24s/it]\n",
      "Validation: 100%|██████████| 19/19 [00:15<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2196 - Train Acc: 0.9106\n",
      "Validation Loss: 0.5830 - Validation Acc: 0.8000\n",
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:58<00:00,  1.23s/it]\n",
      "Validation: 100%|██████████| 19/19 [00:15<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2027 - Train Acc: 0.9175\n",
      "Validation Loss: 0.8639 - Validation Acc: 0.7500\n",
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:57<00:00,  1.22s/it]\n",
      "Validation: 100%|██████████| 19/19 [00:15<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1655 - Train Acc: 0.9298\n",
      "Validation Loss: 0.6550 - Validation Acc: 0.8017\n",
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:57<00:00,  1.22s/it]\n",
      "Validation: 100%|██████████| 19/19 [00:15<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1527 - Train Acc: 0.9404\n",
      "Validation Loss: 0.9439 - Validation Acc: 0.7550\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:57<00:00,  1.23s/it]\n",
      "Validation: 100%|██████████| 19/19 [00:15<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1552 - Train Acc: 0.9404\n",
      "Validation Loss: 0.5879 - Validation Acc: 0.8217\n",
      "\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:57<00:00,  1.22s/it]\n",
      "Validation: 100%|██████████| 19/19 [00:14<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1112 - Train Acc: 0.9553\n",
      "Validation Loss: 0.6696 - Validation Acc: 0.8000\n",
      "\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:56<00:00,  1.22s/it]\n",
      "Validation: 100%|██████████| 19/19 [00:15<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1200 - Train Acc: 0.9560\n",
      "Validation Loss: 0.7652 - Validation Acc: 0.8133\n",
      "\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:55<00:00,  1.21s/it]\n",
      "Validation: 100%|██████████| 19/19 [00:15<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0768 - Train Acc: 0.9709\n",
      "Validation Loss: 0.7281 - Validation Acc: 0.8150\n",
      "\n",
      "Test Accuracy: 0.6666666666666666\n",
      "\n",
      "\n",
      "[['Preprocess' 'Test Accuracy']\n",
      " ['adaptive_masking_bilateral' '0.6666666666666666']]\n",
      "\n",
      "=========================\n",
      "EfficientNetB1 with adaptive_masking_gaussian\n",
      "=========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B1_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B1_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b1_rwightman-bac287d4.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b1_rwightman-bac287d4.pth\n",
      "100%|██████████| 30.1M/30.1M [00:00<00:00, 144MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== adaptive_masking_gaussian =====\n",
      "Original class distribution: Counter({0: 2338, 1: 1149, 2: 1145})\n",
      "Resampled class distribution: Counter({0: 2338, 1: 2338, 2: 2338})\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [01:48<00:00,  1.33it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7120 - Train Acc: 0.7638\n",
      "Validation Loss: 0.5805 - Validation Acc: 0.7383\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [01:50<00:00,  1.32it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4016 - Train Acc: 0.8232\n",
      "Validation Loss: 0.3907 - Validation Acc: 0.8467\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [01:48<00:00,  1.34it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3425 - Train Acc: 0.8506\n",
      "Validation Loss: 0.3831 - Validation Acc: 0.8250\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [01:50<00:00,  1.32it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2671 - Train Acc: 0.8912\n",
      "Validation Loss: 0.4514 - Validation Acc: 0.8233\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [01:47<00:00,  1.34it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2186 - Train Acc: 0.9152\n",
      "Validation Loss: 0.7490 - Validation Acc: 0.8383\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [01:49<00:00,  1.33it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1416 - Train Acc: 0.9424\n",
      "Validation Loss: 0.8818 - Validation Acc: 0.7983\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [01:48<00:00,  1.34it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1484 - Train Acc: 0.9419\n",
      "Validation Loss: 0.4970 - Validation Acc: 0.8150\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [01:49<00:00,  1.33it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0958 - Train Acc: 0.9665\n",
      "Validation Loss: 0.8090 - Validation Acc: 0.8317\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [01:48<00:00,  1.34it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0906 - Train Acc: 0.9665\n",
      "Validation Loss: 0.9284 - Validation Acc: 0.8133\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [01:50<00:00,  1.32it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0656 - Train Acc: 0.9771\n",
      "Validation Loss: 0.6885 - Validation Acc: 0.8217\n",
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [01:48<00:00,  1.34it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0488 - Train Acc: 0.9829\n",
      "Validation Loss: 0.8338 - Validation Acc: 0.8317\n",
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [01:49<00:00,  1.33it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:11<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0593 - Train Acc: 0.9801\n",
      "Validation Loss: 0.8826 - Validation Acc: 0.8250\n",
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [01:49<00:00,  1.32it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0593 - Train Acc: 0.9788\n",
      "Validation Loss: 1.1421 - Validation Acc: 0.7733\n",
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [01:49<00:00,  1.32it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0755 - Train Acc: 0.9741\n",
      "Validation Loss: 0.8479 - Validation Acc: 0.7850\n",
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [01:48<00:00,  1.34it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:13<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0412 - Train Acc: 0.9864\n",
      "Validation Loss: 1.1022 - Validation Acc: 0.8200\n",
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [01:48<00:00,  1.33it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0410 - Train Acc: 0.9866\n",
      "Validation Loss: 0.7684 - Validation Acc: 0.8367\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [01:49<00:00,  1.33it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0302 - Train Acc: 0.9909\n",
      "Validation Loss: 0.7842 - Validation Acc: 0.8383\n",
      "\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [01:48<00:00,  1.33it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0258 - Train Acc: 0.9907\n",
      "Validation Loss: 0.8989 - Validation Acc: 0.8300\n",
      "\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [01:49<00:00,  1.33it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0360 - Train Acc: 0.9875\n",
      "Validation Loss: 1.1395 - Validation Acc: 0.8033\n",
      "\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [01:48<00:00,  1.33it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0466 - Train Acc: 0.9829\n",
      "Validation Loss: 0.8611 - Validation Acc: 0.8067\n",
      "\n",
      "Test Accuracy: 0.6314102564102564\n",
      "\n",
      "\n",
      "[['Preprocess' 'Test Accuracy']\n",
      " ['adaptive_masking_gaussian' '0.6314102564102564']]\n",
      "\n",
      "=========================\n",
      "ResNet50 with adaptive_masking_equalized\n",
      "=========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 166MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== adaptive_masking_equalized =====\n",
      "Original class distribution: Counter({0: 2338, 1: 1149, 2: 1145})\n",
      "Resampled class distribution: Counter({0: 2338, 1: 2338, 2: 2338})\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:02<00:00,  1.19it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6785 - Train Acc: 0.7563\n",
      "Validation Loss: 0.4481 - Validation Acc: 0.8033\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:03<00:00,  1.18it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4434 - Train Acc: 0.8061\n",
      "Validation Loss: 0.4320 - Validation Acc: 0.8083\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:02<00:00,  1.18it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3963 - Train Acc: 0.8232\n",
      "Validation Loss: 0.4887 - Validation Acc: 0.8050\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:03<00:00,  1.17it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3767 - Train Acc: 0.8310\n",
      "Validation Loss: 0.5757 - Validation Acc: 0.7200\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:02<00:00,  1.18it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3653 - Train Acc: 0.8418\n",
      "Validation Loss: 0.7879 - Validation Acc: 0.7233\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:03<00:00,  1.17it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3309 - Train Acc: 0.8577\n",
      "Validation Loss: 0.7697 - Validation Acc: 0.6783\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:03<00:00,  1.18it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2951 - Train Acc: 0.8756\n",
      "Validation Loss: 0.5005 - Validation Acc: 0.7567\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:02<00:00,  1.18it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2737 - Train Acc: 0.8828\n",
      "Validation Loss: 0.4774 - Validation Acc: 0.8000\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:04<00:00,  1.17it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2040 - Train Acc: 0.9147\n",
      "Validation Loss: 0.6111 - Validation Acc: 0.7917\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:04<00:00,  1.17it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1837 - Train Acc: 0.9251\n",
      "Validation Loss: 0.6877 - Validation Acc: 0.7300\n",
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:01<00:00,  1.19it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1360 - Train Acc: 0.9467\n",
      "Validation Loss: 0.9113 - Validation Acc: 0.7217\n",
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:03<00:00,  1.17it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1572 - Train Acc: 0.9421\n",
      "Validation Loss: 0.8239 - Validation Acc: 0.7450\n",
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:03<00:00,  1.18it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0910 - Train Acc: 0.9676\n",
      "Validation Loss: 0.9337 - Validation Acc: 0.7683\n",
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:02<00:00,  1.19it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1091 - Train Acc: 0.9579\n",
      "Validation Loss: 0.9501 - Validation Acc: 0.7567\n",
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:03<00:00,  1.17it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0709 - Train Acc: 0.9732\n",
      "Validation Loss: 0.9570 - Validation Acc: 0.7567\n",
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:03<00:00,  1.17it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0869 - Train Acc: 0.9659\n",
      "Validation Loss: 1.4846 - Validation Acc: 0.7383\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:02<00:00,  1.18it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0812 - Train Acc: 0.9693\n",
      "Validation Loss: 0.9017 - Validation Acc: 0.7883\n",
      "\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:04<00:00,  1.17it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0615 - Train Acc: 0.9775\n",
      "Validation Loss: 1.0793 - Validation Acc: 0.7733\n",
      "\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:03<00:00,  1.17it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0246 - Train Acc: 0.9911\n",
      "Validation Loss: 1.3243 - Validation Acc: 0.7767\n",
      "\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:02<00:00,  1.18it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0568 - Train Acc: 0.9793\n",
      "Validation Loss: 0.9499 - Validation Acc: 0.8000\n",
      "\n",
      "Test Accuracy: 0.6923076923076923\n",
      "\n",
      "\n",
      "[['Preprocess' 'Test Accuracy']\n",
      " ['adaptive_masking_equalized' '0.6923076923076923']]\n",
      "\n",
      "=========================\n",
      "VGG16 with gaussian_blur\n",
      "=========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:08<00:00, 68.1MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== gaussian_blur =====\n",
      "Original class distribution: Counter({0: 2338, 1: 1149, 2: 1145})\n",
      "Resampled class distribution: Counter({0: 2338, 1: 2338, 2: 2338})\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:18<00:00,  1.04it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.1146 - Train Acc: 0.5367\n",
      "Validation Loss: 0.8193 - Validation Acc: 0.6383\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:18<00:00,  1.05it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6649 - Train Acc: 0.7165\n",
      "Validation Loss: 0.6672 - Validation Acc: 0.6117\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:18<00:00,  1.05it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7723 - Train Acc: 0.6949\n",
      "Validation Loss: 1.3261 - Validation Acc: 0.3333\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:16<00:00,  1.07it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.5429 - Train Acc: 0.4985\n",
      "Validation Loss: 1.1937 - Validation Acc: 0.3333\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:18<00:00,  1.05it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0491 - Train Acc: 0.5043\n",
      "Validation Loss: 1.1887 - Validation Acc: 0.3333\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:17<00:00,  1.06it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0439 - Train Acc: 0.5043\n",
      "Validation Loss: 1.1713 - Validation Acc: 0.3333\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:17<00:00,  1.06it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0406 - Train Acc: 0.5047\n",
      "Validation Loss: 1.1636 - Validation Acc: 0.3333\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:14<00:00,  1.07it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0409 - Train Acc: 0.5047\n",
      "Validation Loss: 1.1451 - Validation Acc: 0.3333\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:16<00:00,  1.06it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0405 - Train Acc: 0.5047\n",
      "Validation Loss: 1.1481 - Validation Acc: 0.3333\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:16<00:00,  1.06it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0430 - Train Acc: 0.5047\n",
      "Validation Loss: 1.2021 - Validation Acc: 0.3333\n",
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:16<00:00,  1.07it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0420 - Train Acc: 0.5047\n",
      "Validation Loss: 1.1947 - Validation Acc: 0.3333\n",
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:16<00:00,  1.06it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0410 - Train Acc: 0.5047\n",
      "Validation Loss: 1.1445 - Validation Acc: 0.3333\n",
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:17<00:00,  1.05it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0406 - Train Acc: 0.5047\n",
      "Validation Loss: 1.1500 - Validation Acc: 0.3333\n",
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:19<00:00,  1.04it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0392 - Train Acc: 0.5047\n",
      "Validation Loss: 1.1587 - Validation Acc: 0.3333\n",
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:17<00:00,  1.05it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0403 - Train Acc: 0.5047\n",
      "Validation Loss: 1.1572 - Validation Acc: 0.3333\n",
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:18<00:00,  1.05it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0413 - Train Acc: 0.5047\n",
      "Validation Loss: 1.1534 - Validation Acc: 0.3333\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:17<00:00,  1.06it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0401 - Train Acc: 0.5047\n",
      "Validation Loss: 1.1280 - Validation Acc: 0.3333\n",
      "\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:17<00:00,  1.05it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0413 - Train Acc: 0.5047\n",
      "Validation Loss: 1.1260 - Validation Acc: 0.3333\n",
      "\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:18<00:00,  1.05it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0423 - Train Acc: 0.5047\n",
      "Validation Loss: 1.1822 - Validation Acc: 0.3333\n",
      "\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 145/145 [02:17<00:00,  1.05it/s]\n",
      "Validation: 100%|██████████| 19/19 [00:12<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0418 - Train Acc: 0.5047\n",
      "Validation Loss: 1.1466 - Validation Acc: 0.3333\n",
      "\n",
      "Test Accuracy: 0.38782051282051283\n",
      "\n",
      "\n",
      "[['Preprocess' 'Test Accuracy']\n",
      " ['gaussian_blur' '0.38782051282051283']]\n"
     ]
    }
   ],
   "source": [
    "# Use the oversampled dataset\n",
    "root=\"dataset/new_data\"\n",
    "# DenseNet161 with adaptive_masking_bilateral\n",
    "print(\"\\n=========================\\nDenseNet161 with adaptive_masking_bilateral\\n=========================\")\n",
    "model = models.densenet161(pretrained=True)\n",
    "results = model_pipelines(model, \"DenseNet161\", root=root, preprocess=[\"adaptive_masking_bilateral\"])\n",
    "print(results)\n",
    "\n",
    "# EfficientNetB1 with adaptive_masking_gaussian\n",
    "print(\"\\n=========================\\nEfficientNetB1 with adaptive_masking_gaussian\\n=========================\")\n",
    "model = models.efficientnet_b1(pretrained=True)\n",
    "results = model_pipelines(model, \"EfficientNetB1\", root=root, preprocess=[\"adaptive_masking_gaussian\"])\n",
    "print(results)\n",
    "\n",
    "# ResNet50 with adaptive_masking_equalized\n",
    "print(\"\\n=========================\\nResNet50 with adaptive_masking_equalized\\n=========================\")\n",
    "model = models.resnet50(pretrained=True)\n",
    "results = model_pipelines(model, \"ResNet50\", root=root, preprocess=[\"adaptive_masking_equalized\"])\n",
    "print(results)\n",
    "\n",
    "# VGG16 with adaptive_masking\n",
    "print(\"\\n=========================\\nVGG16 with gaussian_blur\\n=========================\")\n",
    "model = models.vgg16(pretrained=True)\n",
    "results = model_pipelines(model, \"VGG16\", root=root, preprocess=[\"gaussian_blur\"])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model &amp; Preprocess</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DenseNet161 with adaptive_masking_bilateral</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EfficientNetB1 with adaptive_masking_gaussian</td>\n",
       "      <td>63.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ResNet50 with adaptive_masking_equalized</td>\n",
       "      <td>69.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VGG16 with gaussian_blur</td>\n",
       "      <td>38.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model & Preprocess  Test Accuracy\n",
       "0    DenseNet161 with adaptive_masking_bilateral          66.67\n",
       "1  EfficientNetB1 with adaptive_masking_gaussian          63.14\n",
       "2       ResNet50 with adaptive_masking_equalized          69.23\n",
       "3                       VGG16 with gaussian_blur          38.78"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data for the comparison table of the four models with their preprocess techniques and test accuracies\n",
    "model_comparison_data = {\n",
    "    \"Model & Preprocess\": [\n",
    "        \"DenseNet161 with adaptive_masking_bilateral\",\n",
    "        \"EfficientNetB1 with adaptive_masking_gaussian\",\n",
    "        \"ResNet50 with adaptive_masking_equalized\",\n",
    "        \"VGG16 with gaussian_blur\"\n",
    "    ],\n",
    "    \"Test Accuracy\": [\n",
    "        \"0.6666666666666666\",\n",
    "        \"0.6314102564102564\",\n",
    "        \"0.6923076923076923\",\n",
    "        \"0.38782051282051283\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Creating the comparison DataFrame\n",
    "model_comparison_df = pd.DataFrame(model_comparison_data)\n",
    "model_comparison_df[\"Test Accuracy\"] = model_comparison_df[\"Test Accuracy\"].astype(float) * 100\n",
    "model_comparison_df.to_csv(\"results/2_oversampling_model_comparison.csv\", index=False)\n",
    "\n",
    "model_comparison_df = model_comparison_df.round(2)\n",
    "model_comparison_df"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
