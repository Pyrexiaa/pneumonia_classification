{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10300818,"sourceType":"datasetVersion","datasetId":6217278}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import all necessary libraries first\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, models, datasets\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix, classification_report, f1_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Image settings\nIMG_SIZE = 240\nBATCH_SIZE = 32\nNUM_WORKERS = 4\n\nclass GaussianBlur:\n    \"\"\"Custom transform for Gaussian Blur\"\"\"\n    def __call__(self, img):\n        np_img = np.array(img)\n        blurred = cv2.GaussianBlur(np_img, (3,3), 0)\n        return transforms.functional.to_tensor(blurred)\n\n# Define core preprocessing (applied to all splits)\ncore_transforms = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    GaussianBlur(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Additional augmentation for training only\ntrain_transforms = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    transforms.RandomAffine(0, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n    GaussianBlur(),  # Same Gaussian blur as in core transforms\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Validation/Test transforms are just the core transforms\nval_transforms = core_transforms\ntest_transforms = core_transforms\n\n# Load datasets\ndef load_data():\n    train_dataset = datasets.ImageFolder(\n        root='/kaggle/input/chest-xray/chest_xray_jj_811/train',\n        transform=train_transforms\n    )\n    \n    val_dataset = datasets.ImageFolder(\n        root='/kaggle/input/chest-xray/chest_xray_jj_811/val',\n        transform=val_transforms\n    )\n    \n    test_dataset = datasets.ImageFolder(\n        root='/kaggle/input/chest-xray/chest_xray_jj_811/test',\n        transform=val_transforms\n    )\n    \n    train_loader = DataLoader(\n        train_dataset, \n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        num_workers=NUM_WORKERS\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=False,\n        num_workers=NUM_WORKERS\n    )\n    \n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=False,\n        num_workers=NUM_WORKERS\n    )\n    \n    return train_loader, val_loader, test_loader\n\ntrain_loader, val_loader, test_loader = load_data()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ChestXrayModel(nn.Module):\n    def __init__(self):\n        super(ChestXrayModel, self).__init__()\n        # Load pretrained EfficientNetB1\n        self.efficientnet = models.efficientnet_b1(pretrained=True)\n        \n        # Freeze base model parameters\n        for param in self.efficientnet.parameters():\n            param.requires_grad = False\n            \n        # Modify classifier\n        num_ftrs = self.efficientnet.classifier[1].in_features\n        self.efficientnet.classifier = nn.Sequential(\n            nn.Dropout(p=0.2),\n            nn.Linear(num_ftrs, 128),\n            nn.ReLU(),\n            nn.Dropout(p=0.2),\n            nn.Linear(128, 3)\n        )\n        \n    def forward(self, x):\n        return self.efficientnet(x)\n\ndef train_epoch(model, loader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for inputs, labels in tqdm(loader, desc='Training'):\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        _, predictions = torch.max(outputs, 1)\n        correct += (predictions == labels).sum().item()\n        total += labels.size(0)\n        \n    return running_loss / len(loader), correct / total\n\ndef validate(model, loader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for inputs, labels in tqdm(loader, desc='Validation'):\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            \n            running_loss += loss.item()\n            _, predictions = torch.max(outputs, 1)\n            correct += (predictions == labels).sum().item()\n            total += labels.size(0)\n    \n    return running_loss / len(loader), correct / total\n\n# Initialize history dictionary for both phases\nhistory = {\n    'phase1': {\n        'train_loss': [],\n        'val_loss': [],\n        'train_acc': [],\n        'val_acc': []\n    },\n    'phase2': {\n        'train_loss': [],\n        'val_loss': [],\n        'train_acc': [],\n        'val_acc': []\n    }\n}\n# Load data\ntrain_loader, val_loader, test_loader = load_data()\n\n# Initialize model\nmodel = ChestXrayModel().to(device)\ncriterion = nn.CrossEntropyLoss()\n\n# First training phase with frozen base\nprint(\"Phase 1: Training with frozen base model...\")\noptimizer = optim.Adam(model.efficientnet.classifier.parameters(), lr=0.001)\n\nfor epoch in range(20):\n    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n    val_loss, val_acc = validate(model, val_loader, criterion, device)\n    \n    # Save metrics for phase 1\n    history['phase1']['train_loss'].append(train_loss)\n    history['phase1']['val_loss'].append(val_loss)\n    history['phase1']['train_acc'].append(train_acc)\n    history['phase1']['val_acc'].append(val_acc)\n    \n    print(f'Epoch {epoch+1}/20:')\n    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\\n')\n\n# Unfreeze last few layers for fine-tuning\nprint(\"\\nPhase 2: Fine-tuning model...\")\nfor param in model.efficientnet.features[-3:].parameters():\n    param.requires_grad = True\n\noptimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001)\n\nfor epoch in range(20):\n    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n    val_loss, val_acc = validate(model, val_loader, criterion, device)\n    \n    # Save metrics for phase 2\n    history['phase2']['train_loss'].append(train_loss)\n    history['phase2']['val_loss'].append(val_loss)\n    history['phase2']['train_acc'].append(train_acc)\n    history['phase2']['val_acc'].append(val_acc)\n    \n    print(f'Fine-tuning Epoch {epoch+1}/12:')\n    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\\n')\n\n# Save model and complete history\ntorch.save({\n    'model_state_dict': model.state_dict(),\n    'history': history\n}, 'chest_xray_model_complete.pth')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_test_data(test_dir='/kaggle/input/chest-xray/chest_xray_jj_811/test', batch_size=32):\n    \"\"\"Load the test dataset with proper transforms\"\"\"\n    # Define core preprocessing (same as training, but without augmentation)\n    test_transforms = transforms.Compose([\n        transforms.Resize((240, 240)),\n        GaussianBlur(),  # Same Gaussian blur as in training\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    # Load test dataset\n    test_dataset = datasets.ImageFolder(\n        root=test_dir,\n        transform=test_transforms\n    )\n\n    # Create test dataloader\n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=batch_size,\n        shuffle=False,  # Don't shuffle test data\n        num_workers=4\n    )\n\n    return test_loader\n    \ndef evaluate_model(model_path, test_loader, device):\n    \"\"\"Complete model evaluation on test set\"\"\"\n    # Load the trained model\n    checkpoint = torch.load(model_path)\n    model = ChestXrayModel()  # Make sure this matches your training architecture\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model = model.to(device)\n    model.eval()  # Set to evaluation mode\n    \n    # Get predictions on test set\n    all_predictions = []\n    all_labels = []\n    \n    with torch.no_grad():  # No gradient computation needed for testing\n        for inputs, labels in test_loader:\n            inputs = inputs.to(device)\n            outputs = model(inputs)  # Remove squeeze since we have 3 outputs\n            _, predictions = torch.max(outputs, 1)  # Get class with highest probability\n            \n            all_predictions.extend(predictions.cpu().numpy())\n            all_labels.extend(labels.numpy())\n    \n    # Convert to numpy arrays\n    all_predictions = np.array(all_predictions)\n    all_labels = np.array(all_labels)\n    \n    # Calculate metrics\n    # Use 'macro' average for multi-class\n    f1 = f1_score(all_labels, all_predictions, average='macro')\n    conf_matrix = confusion_matrix(all_labels, all_predictions)\n    class_report = classification_report(all_labels, all_predictions)\n    \n    # Get class names from test loader\n    class_names = test_loader.dataset.classes\n    \n    # Plot confusion matrix with class labels\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n                xticklabels=class_names,\n                yticklabels=class_names)\n    plt.title('Confusion Matrix on Test Set')\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.show()\n    \n    # Print metrics\n    print(\"\\nTest Set Metrics:\")\n    print(f\"Macro F1 Score: {f1:.4f}\")\n    print(\"\\nClassification Report:\")\n    print(class_report)\n    \n    # Plot training history if available\n    if 'history' in checkpoint:\n        plot_complete_training_history(checkpoint['history'])\n    \n    return {\n        'f1_score': f1,\n        'confusion_matrix': conf_matrix,\n        'predictions': all_predictions,\n        'true_labels': all_labels,\n        'class_names': class_names\n    }\n\n# Add this function to plot per-class metrics\ndef plot_per_class_metrics(results):\n    \"\"\"Plot per-class precision, recall, and F1 scores\"\"\"\n    class_names = results['class_names']\n    report = classification_report(results['true_labels'], \n                                 results['predictions'], \n                                 output_dict=True)\n    \n    # Extract per-class metrics\n    metrics = []\n    for class_name in class_names:\n        metrics.append({\n            'Class': class_name,\n            'Precision': report[str(class_names.index(class_name))]['precision'],\n            'Recall': report[str(class_names.index(class_name))]['recall'],\n            'F1-Score': report[str(class_names.index(class_name))]['f1-score']\n        })\n    \n    # Create DataFrame for plotting\n    df_metrics = pd.DataFrame(metrics)\n    \n    # Plot\n    plt.figure(figsize=(12, 6))\n    x = np.arange(len(class_names))\n    width = 0.25\n    \n    plt.bar(x - width, df_metrics['Precision'], width, label='Precision')\n    plt.bar(x, df_metrics['Recall'], width, label='Recall')\n    plt.bar(x + width, df_metrics['F1-Score'], width, label='F1-Score')\n    \n    plt.ylabel('Score')\n    plt.title('Per-class Performance Metrics')\n    plt.xticks(x, class_names, rotation=45)\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n\ndef plot_complete_training_history(history):\n    \"\"\"Plot training history metrics for both phases\"\"\"\n    plt.figure(figsize=(15, 5))\n    \n    # Combine histories from both phases\n    train_loss = history['phase1']['train_loss'] + history['phase2']['train_loss']\n    val_loss = history['phase1']['val_loss'] + history['phase2']['val_loss']\n    train_acc = history['phase1']['train_acc'] + history['phase2']['train_acc']\n    val_acc = history['phase1']['val_acc'] + history['phase2']['val_acc']\n    \n    # Create epoch numbers for x-axis\n    epochs = range(1, len(train_loss) + 1)\n    phase1_end = len(history['phase1']['train_loss'])\n    \n    # Plot Loss\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, train_loss, label='Train Loss')\n    plt.plot(epochs, val_loss, label='Validation Loss')\n    plt.axvline(x=phase1_end, color='r', linestyle='--', \n                label='Start of Fine-tuning')\n    plt.title('Model Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    # Plot Accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, train_acc, label='Train Accuracy')\n    plt.plot(epochs, val_acc, label='Validation Accuracy')\n    plt.axvline(x=phase1_end, color='r', linestyle='--', \n                label='Start of Fine-tuning')\n    plt.title('Model Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.show()\n\n# Usage:\ntest_loader = load_test_data()\nresults = evaluate_model('chest_xray_model_complete.pth', test_loader, device)\nplot_per_class_metrics(results)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}